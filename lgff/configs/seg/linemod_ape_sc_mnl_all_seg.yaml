# =========================================
# LGFF Single-Class Config (LINEMOD - APE)
# Manifold-aware + Hybrid Loss 版本
# =========================================

# ---------- Dataset / BOP ----------
dataset_name: "bop-single"

# 指向完整的 BOP 数据集根目录（LINEMOD = lm）。
# 训练/评估时只会通过 obj_id=1 过滤出 ape 的图像。
dataset_root: "/home/xyh/PycharmProjects/FFB6D-high-pytorch/lgff/data/linemod_ape_crop128_all"

obj_id: 1
num_points: 1024
num_keypoints: 8
#val_split: "test"               # 与裁剪脚本输出的 split 对齐

# 裁剪后输入尺寸
resize_h: 128
resize_w: 128

# 深度缩放（BOP 默认毫米 -> 米）
depth_scale: 1000.0

# ---------- Dataloader ----------
batch_size: 32
num_workers: 8

# ---------- Training Hyper-params ----------
epochs: 50
lr: 0.0001
weight_decay: 0.00001
use_amp: true
log_interval: 20

# LR Scheduler（plateau / cosine / step / none）
scheduler: "plateau"
lr_patience: 10
lr_factor: 0.5
lr_min: 0.000001
lr_step_size: 30

# 梯度裁剪
max_grad_norm: 2.0

# ---------- Model / Backbone ----------
backbone_name: "mobilenet_v3_large"
backbone_arch: "large"
backbone_output_stride: 8
backbone_pretrained: true
backbone_freeze_bn: true

backbone_return_intermediate: true
backbone_low_level_index: 3

rgb_feat_dim: 128
geo_feat_dim: 128

# ---------- PointNet Branch ----------
point_input_dim: 3
point_hidden_dims: [64, 128]
point_norm: "bn"
point_use_se: true
point_dropout: 0.0

# ---------- Head ----------
head_hidden_dim: 128
head_feat_dim: 64
head_dropout: 0.0

# ======================================================
# Loss & Symmetry（新：Dense + Rot + CAD + KP 混合）
# ======================================================
w_rate: 0.015          # DenseFusion 中 conf 正则项系数
sym_class_ids: []      # ape 非对称物体

# 主几何 Loss 权重（新版 LGFFLoss 中的 lambda_*）

lambda_dense: 1.0
lambda_t: 1.0
lambda_conf: 0.05
lambda_kp_of: 1.0 # 先给 0.2，观察 loss_kp_of 曲线与占比


t_z_weight: 3.0
conf_alpha: 12.0
conf_dist_max: 0.025

# 使用与 Evaluator 一致的融合姿态做监督（平移 + CAD ADD）
loss_use_fused_pose: false

# （如果你在 LGFFLoss 中加了开关，可以保留；否则可忽略）
use_geodesic_rot: true

# ======================================================
# Curriculum & Uncertainty（TrainerSC / LGFFLoss 用）
# ======================================================

# 是否启用 coarse-to-fine 课程式权重调度：
#   前期 lambda_t / lambda_rot 较大，帮助快速对齐位姿参数；
#   后期逐步减弱，让 dense / kp_of 等几何项主导精修。
use_curriculum_loss: false
curriculum_warmup_frac: 0.4      # 前 40% epoch 保持原始权重
curriculum_final_factor_t: 0.3   # 末期 lambda_t 衰减到 0.3 * 初始
curriculum_final_factor_rot: 0.3 # 末期 lambda_rot 衰减到 0.3 * 初始

# 多任务同方差不确定性权重（如果你在 LGFFLoss 中实现了，可直接打开做实验）
use_uncertainty_weighting: false

# ======================================================
# Pose 融合 / 评估阈值（与 EvaluatorSC 对齐）
# ======================================================

# 姿态融合策略（fuse_pose_from_outputs 用到的配置，保持原来习惯即可）
train_use_best_point: true    # 训练阶段内部融合时：默认使用 best point 作为基准
#eval_use_best_point: true     # 评估阶段同样使用 best point（可后续试 top-k 融合）
eval_topk: 8                  # 若使用 top-k 融合，可通过 cfg 控制 k 值


# CMD & obj 直径（单位 m）
cmd_threshold_m: 0.02
obj_diameter_m: 0.1016561314   # eval log 中估计得到的 ape 直径，可写死进配置


return_mask: true

# ===== model switch =====
model_variant: sc_seg
loss_variant: seg

# ===== pose fusion (use point-valid mask) =====
pose_fusion_use_valid_mask: true
pose_fusion_valid_mask_source: labels     # labels / seg
pose_fusion_conf_floor: 1.0e-4

# ===== seg head =====
use_seg_head: true
lambda_seg: 0.2

seg_head_in: rgb                          # rgb / fused (看你实现支持什么)
seg_head_channels: 64
seg_output_stride: 4                      # 对 point-seg 基本无影响，保留即可

seg_loss_type: bce_dice                   # bce / bce_dice
seg_pos_weight: null
seg_ignore_invalid: true                  # 使用 labels==0 的点做 ignore
seg_detach_trunk: true                    # 稳：先不让 seg 反向冲击 trunk

# ===== seg supervision =====
seg_supervision: point
seg_supervision_source: labels            # labels / pcld_valid_mask



# ---------- Logging / Output ----------
log_dir: "/home/xyh/PycharmProjects/FFB6D-high-pytorch/output/linemod_ape_sc_mnl_all_seg"
# 不写 work_dir 会默认使用 log_dir
